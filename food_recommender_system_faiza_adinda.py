# -*- coding: utf-8 -*-
"""Food Recommender System_Faiza Adinda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k1C284ZDHzRRb6xSODpSq-6xvnP3i0B-

# Import Library
"""

# Import seluruh library yang dipakai
import pandas as pd
import numpy as np
import os, shutil
import zipfile
import matplotlib.pyplot as plt
import seaborn as sns
import re
import tensorflow as tf
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Flatten, Dot, Dense, Concatenate, Dropout

"""# Data Loading"""

# Mengupload file kaggle.json untuk mengambil dataset
from google.colab import files
files.upload()

# Mengambil dataset
os.makedirs('/root/.kaggle', exist_ok=True)
!cp kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json
!kaggle datasets download -d schemersays/food-recommendation-system
!unzip food-recommendation-system.zip

# Membaca dataset yang telah diunggah ke dalam dataframe
food = pd.read_csv('/content/1662574418893344.csv')
rating = pd.read_csv('/content/ratings.csv')

# Melihat data food
food

# Melihat data rating
rating

"""# Data Understanding"""

# Melihat info umum dataset (fitur, type data, jumlah entry, dan nilai null)
print("Food Info:")
print(food.info())
print("\nRatings Info:")
print(rating.info())

# Melihat apakah ada missing value
print("Missing values in movies:\n", food.isnull().sum())
print("Missing values in ratings:\n", rating.isnull().sum())

# Melihat apakah ada nilai duplikat
print("Duplicated rows in movies:", food.duplicated().sum())
print("Duplicated rows in ratings:", rating.duplicated().sum())

# Melihat nilai unik makanan dan course makanan
print("Jumlah unique nama makanan:", food['Name'].nunique())
print("Jumlah unique Course:", food['C_Type'].nunique())

# Melihat statistik deskriptif data rating
rating.describe()

# Ukuran plot default
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (8, 4)

# Visualisasi distribusi kolom C_Type: Jenis makanan
sns.countplot(y='C_Type', data=food, palette='viridis')
plt.title('Distribusi Jenis Makanan (C_Type)')
plt.xlabel('Jumlah')
plt.ylabel('Kategori')
plt.show()

# Visualisasi distribusi kolom Veg_Non: Vegetarian vs Non-Vegetarian
sns.countplot(x='Veg_Non', data=food, palette='viridis')
plt.title('Distribusi Veg vs Non-Veg')
plt.xlabel('Tipe Makanan')
plt.ylabel('Jumlah')
plt.show()

# Visualisasi distribusi kolom Rating
sns.countplot(x='Rating', data=rating, palette='viridis')
plt.title('Distribusi Rating')
plt.xlabel('Rating')
plt.ylabel('Jumlah')

"""# Data Preparation"""

# Menghapus missing value pada data rating
rating.dropna(axis=0 ,inplace=True)

# Cek kembali missing value
print("Missing values in ratings:\n", rating.isnull().sum())

# Mengubah type data User_ID, Food_ID, dan Rating
rating['User_ID'] = rating['User_ID'].astype(int)
rating['Food_ID'] = rating['Food_ID'].astype(int)
rating['Rating'] = rating['Rating'].astype(float)

# Membersihkan teks dari karakter non-alfanumerik dan mengubahnya ke huruf kecil
# Tujuan: Standarisasi format teks untuk mencegah inkonsistensi data (misal: 'Indian' dan 'indian' dianggap berbeda)
def clean_text(text):
    if isinstance(text, str):
        return re.sub(r'[^a-zA-Z0-9 ]', '', text.lower())
    return ''

# Menerapkan fungsi pembersihan teks ke kolom-kolom teks pada dataset
food['Name'] = food['Name'].apply(clean_text)
food['C_Type'] = food['C_Type'].apply(clean_text)
food['Veg_Non'] = food['Veg_Non'].apply(clean_text)
food['Describe'] = food['Describe'].apply(clean_text)

"""# Modelling Content Based Filtering"""

# Menggabungkan kolom teks menjadi satu kolom 'combined' untuk TF-IDF
food['combined'] = food['Name'] + ' ' + food['C_Type'] + ' '  + ' ' + food['Describe']

# Menerapkan TfidfVectorizer untuk menghasilkan representasi vektor dari teks.
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(food['combined'])

# Menghitung tingkat kemiripan antar makanan berdasarkan teks tersebut
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

# Membuat fungsi untuk merekomendasikan sistem
def recommend_food(input_name, cosine_sim=cosine_sim):
    # Reset index untuk memastikan urutan index sesuai cosine_sim
    food_reset = food.reset_index()

    # Cari makanan yang mengandung input keyword (case-insensitive)
    matches = food_reset[food_reset['Name'].str.lower().str.contains(input_name.lower())]
    if matches.empty:
        return f"Makanan yang mengandung '{input_name}' tidak ditemukan dalam data."
    idx = matches.index[0]

    # Hitung similarity
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]  # top 5 recommendation

    food_indices = [i[0] for i in sim_scores]

    return food_reset[['Name', 'C_Type', 'Describe']].iloc[food_indices]

# Tes model
recommend_food('pasta')

"""# Modelling Collaborative Filtering"""

# Encoding ID Pengguna dan Makanan
user_encoder = LabelEncoder()
item_encoder = LabelEncoder()

rating['user'] = user_encoder.fit_transform(rating['User_ID'])
rating['item'] = item_encoder.fit_transform(rating['Food_ID'])

# Deklarasian variabel fitur (x) dan target (y) untuk proses pelatihan model
x = rating[['user', 'item']].values
y = rating['Rating'].values

# Split dataset
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Membangun model
num_users = len(user_encoder.classes_)
num_items = len(item_encoder.classes_)
embedding_size = 50

user_input = Input(shape=(1,))
user_embedding = Embedding(num_users, embedding_size)(user_input)
user_vec = Flatten()(user_embedding)

item_input = Input(shape=(1,))
item_embedding = Embedding(num_items, embedding_size)(item_input)
item_vec = Flatten()(item_embedding)

# Concatenate + Dense layers
concatenated = Concatenate()([user_vec, item_vec])
x = Dense(128, activation='relu')(concatenated)
x = Dropout(0.3)(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(1)(x)

model = Model([user_input, item_input], output)
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Train model
history = model.fit([x_train[:,0], x_train[:,1]], y_train,
          validation_data=([x_test[:,0], x_test[:,1]], y_test),
          epochs=20, batch_size=16)

# Membuat fungsi rekomendasi makanan kepada pengguna tertentu
def recommend_for_user(user_Id, top_n=10):
    user_idx = user_encoder.transform([user_Id])[0]
    all_items = np.arange(num_items)
    user_array = np.full_like(all_items, user_idx)

    predictions = model.predict([user_array, all_items], verbose=0).flatten()
    top_indices = predictions.argsort()[-top_n:][::-1]

    recommended_item_ids = item_encoder.inverse_transform(top_indices)

    return food[food['Food_ID'].isin(recommended_item_ids)][['Food_ID', 'Name', 'C_Type', 'Veg_Non']]

# Tes model
recommend_for_user('5')

"""# Evaluasi

### Evaluasi CBF
"""

# Membuat fungsi untuk menghitung presisi model
def precision_at_k(query_food_name, recommendations, food_data):
    matches = food_data[food_data['Name'].str.lower().str.contains(query_food_name.lower())]
    if matches.empty:
        return f"Makanan '{query_food_name}' tidak ditemukan dalam data."

    # Ambil C_Type dari hasil match pertama
    query_type = matches.iloc[0]['C_Type'].lower().strip()

    # Hitung jumlah rekomendasi yang punya C_Type yang sama
    relevant_count = sum(
        rec_type.lower().strip() == query_type
        for rec_type in recommendations['C_Type']
    )

    precision = relevant_count / len(recommendations)
    return precision

# Menghitung presisi
recs = recommend_food('kimchi', cosine_sim)
precision = precision_at_k('kimchi', recs, food)
print(f'Precision: {precision:.2f}')

"""Dalam pengujian dengan input makanan "kimchi", dari lima hasil rekomendasi teratas yang dihasilkan oleh sistem, sebanyak empat memiliki kategori yang sama. Sehingga, nilai Precision@5 yang dihasilkan adalah 0.80, atau 80%.

### Evaluasi CF
"""

# Membuat visualisasi untuk model metrik
plt.plot(history.history['loss'])
plt.plot(history.history['mae'])
plt.title('model_metrics')
plt.ylabel('mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""Model berhasil belajar dengan baik dan mencapai konvergensi. Selisih antara train loss dan validation loss juga tidak terlalu jauh, yang menunjukkan bahwa model model tidak mengalami overfitting secara signifikan. Selain itu, nilai MAE validasi yang konsisten di kisaran 2.7 menandakan bahwa prediksi model cukup stabil dan dapat diandalkan untuk merekomendasikan makanan berdasarkan preferensi pengguna."""